{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3c0bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# ðŸŒ¾ Wereng Classification Model Training\\n\",\n",
    "    \"\\n\",\n",
    "    \"Notebook untuk training model klasifikasi hama wereng menggunakan Transfer Learning (MobileNetV2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Dataset Structure:**\\n\",\n",
    "    \"```\\n\",\n",
    "    \"dataset/\\n\",\n",
    "    \"â”œâ”€â”€ train/\\n\",\n",
    "    \"â”‚   â”œâ”€â”€ wereng_coklat/\\n\",\n",
    "    \"â”‚   â”œâ”€â”€ wereng_hijau/\\n\",\n",
    "    \"â”‚   â”œâ”€â”€ wereng_punggung_putih/\\n\",\n",
    "    \"â”‚   â””â”€â”€ bukan_wereng/\\n\",\n",
    "    \"â””â”€â”€ validation/\\n\",\n",
    "    \"    â”œâ”€â”€ wereng_coklat/\\n\",\n",
    "    \"    â”œâ”€â”€ wereng_hijau/\\n\",\n",
    "    \"    â”œâ”€â”€ wereng_punggung_putih/\\n\",\n",
    "    \"    â””â”€â”€ bukan_wereng/\\n\",\n",
    "    \"```\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Import Libraries\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow import keras\\n\",\n",
    "    \"from tensorflow.keras import layers, models\\n\",\n",
    "    \"from tensorflow.keras.applications import MobileNetV2\\n\",\n",
    "    \"from tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\",\n",
    "    \"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"TensorFlow version: {tf.__version__}\\\")\\n\",\n",
    "    \"print(f\\\"GPU available: {tf.config.list_physical_devices('GPU')}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Configuration\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Paths\\n\",\n",
    "    \"TRAIN_DIR = 'dataset/train'\\n\",\n",
    "    \"VAL_DIR = 'dataset/validation'\\n\",\n",
    "    \"MODEL_SAVE_PATH = 'app/models/wereng_classifier.h5'\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Hyperparameters\\n\",\n",
    "    \"IMG_SIZE = (224, 224)\\n\",\n",
    "    \"BATCH_SIZE = 32\\n\",\n",
    "    \"EPOCHS = 50\\n\",\n",
    "    \"LEARNING_RATE = 0.0001\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Classes\\n\",\n",
    "    \"CLASS_NAMES = [\\n\",\n",
    "    \"    'wereng_coklat',\\n\",\n",
    "    \"    'wereng_hijau', \\n\",\n",
    "    \"    'wereng_punggung_putih',\\n\",\n",
    "    \"    'bukan_wereng'\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"NUM_CLASSES = len(CLASS_NAMES)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Number of classes: {NUM_CLASSES}\\\")\\n\",\n",
    "    \"print(f\\\"Classes: {CLASS_NAMES}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Data Preparation & Augmentation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Data augmentation untuk training\\n\",\n",
    "    \"train_datagen = ImageDataGenerator(\\n\",\n",
    "    \"    rescale=1./255,\\n\",\n",
    "    \"    rotation_range=20,\\n\",\n",
    "    \"    width_shift_range=0.2,\\n\",\n",
    "    \"    height_shift_range=0.2,\\n\",\n",
    "    \"    shear_range=0.2,\\n\",\n",
    "    \"    zoom_range=0.2,\\n\",\n",
    "    \"    horizontal_flip=True,\\n\",\n",
    "    \"    fill_mode='nearest'\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Hanya rescaling untuk validation\\n\",\n",
    "    \"val_datagen = ImageDataGenerator(rescale=1./255)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load training data\\n\",\n",
    "    \"train_generator = train_datagen.flow_from_directory(\\n\",\n",
    "    \"    TRAIN_DIR,\\n\",\n",
    "    \"    target_size=IMG_SIZE,\\n\",\n",
    "    \"    batch_size=BATCH_SIZE,\\n\",\n",
    "    \"    class_mode='categorical',\\n\",\n",
    "    \"    classes=CLASS_NAMES,\\n\",\n",
    "    \"    shuffle=True\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load validation data\\n\",\n",
    "    \"val_generator = val_datagen.flow_from_directory(\\n\",\n",
    "    \"    VAL_DIR,\\n\",\n",
    "    \"    target_size=IMG_SIZE,\\n\",\n",
    "    \"    batch_size=BATCH_SIZE,\\n\",\n",
    "    \"    class_mode='categorical',\\n\",\n",
    "    \"    classes=CLASS_NAMES,\\n\",\n",
    "    \"    shuffle=False\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nTraining samples: {train_generator.samples}\\\")\\n\",\n",
    "    \"print(f\\\"Validation samples: {val_generator.samples}\\\")\\n\",\n",
    "    \"print(f\\\"Class indices: {train_generator.class_indices}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Visualize Sample Images\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualisasi beberapa gambar training\\n\",\n",
    "    \"def show_sample_images(generator, num_images=9):\\n\",\n",
    "    \"    images, labels = next(generator)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=(12, 12))\\n\",\n",
    "    \"    for i in range(min(num_images, len(images))):\\n\",\n",
    "    \"        plt.subplot(3, 3, i + 1)\\n\",\n",
    "    \"        plt.imshow(images[i])\\n\",\n",
    "    \"        class_idx = np.argmax(labels[i])\\n\",\n",
    "    \"        plt.title(CLASS_NAMES[class_idx])\\n\",\n",
    "    \"        plt.axis('off')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"show_sample_images(train_generator)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Build Model (Transfer Learning - MobileNetV2)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def create_model(num_classes, img_size=(224, 224)):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Create model using MobileNetV2 with transfer learning\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Load MobileNetV2 pre-trained on ImageNet\\n\",\n",
    "    \"    base_model = MobileNetV2(\\n\",\n",
    "    \"        input_shape=(*img_size, 3),\\n\",\n",
    "    \"        include_top=False,\\n\",\n",
    "    \"        weights='imagenet'\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Freeze base model layers\\n\",\n",
    "    \"    base_model.trainable = False\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create new model\\n\",\n",
    "    \"    model = models.Sequential([\\n\",\n",
    "    \"        base_model,\\n\",\n",
    "    \"        layers.GlobalAveragePooling2D(),\\n\",\n",
    "    \"        layers.Dropout(0.5),\\n\",\n",
    "    \"        layers.Dense(256, activation='relu'),\\n\",\n",
    "    \"        layers.Dropout(0.3),\\n\",\n",
    "    \"        layers.Dense(num_classes, activation='softmax')\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return model, base_model\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create model\\n\",\n",
    "    \"model, base_model = create_model(NUM_CLASSES, IMG_SIZE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Compile model\\n\",\n",
    "    \"model.compile(\\n\",\n",
    "    \"    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\\n\",\n",
    "    \"    loss='categorical_crossentropy',\\n\",\n",
    "    \"    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')]\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Setup Callbacks\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create models directory if not exists\\n\",\n",
    "    \"os.makedirs('app/models', exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Callbacks\\n\",\n",
    "    \"checkpoint = ModelCheckpoint(\\n\",\n",
    "    \"    MODEL_SAVE_PATH,\\n\",\n",
    "    \"    monitor='val_accuracy',\\n\",\n",
    "    \"    save_best_only=True,\\n\",\n",
    "    \"    mode='max',\\n\",\n",
    "    \"    verbose=1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"early_stopping = EarlyStopping(\\n\",\n",
    "    \"    monitor='val_loss',\\n\",\n",
    "    \"    patience=10,\\n\",\n",
    "    \"    restore_best_weights=True,\\n\",\n",
    "    \"    verbose=1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"reduce_lr = ReduceLROnPlateau(\\n\",\n",
    "    \"    monitor='val_loss',\\n\",\n",
    "    \"    factor=0.5,\\n\",\n",
    "    \"    patience=5,\\n\",\n",
    "    \"    min_lr=1e-7,\\n\",\n",
    "    \"    verbose=1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"callbacks = [checkpoint, early_stopping, reduce_lr]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Train Model (Phase 1: Frozen Base)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "    \"print(\\\"PHASE 1: Training with frozen base model\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50 + \\\"\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"history_phase1 = model.fit(\\n\",\n",
    "    \"    train_generator,\\n\",\n",
    "    \"    epochs=20,\\n\",\n",
    "    \"    validation_data=val_generator,\\n\",\n",
    "    \"    callbacks=callbacks,\\n\",\n",
    "    \"    verbose=1\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Fine-tuning (Phase 2: Unfreeze Some Layers)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "    \"print(\\\"PHASE 2: Fine-tuning (unfreezing top layers)\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50 + \\\"\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Unfreeze the top layers of the base model\\n\",\n",
    "    \"base_model.trainable = True\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Freeze all layers except the last 20\\n\",\n",
    "    \"for layer in base_model.layers[:-20]:\\n\",\n",
    "    \"    layer.trainable = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Recompile with lower learning rate\\n\",\n",
    "    \"model.compile(\\n\",\n",
    "    \"    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE/10),\\n\",\n",
    "    \"    loss='categorical_crossentropy',\\n\",\n",
    "    \"    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')]\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Number of trainable layers: {len([l for l in model.layers if l.trainable])}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Continue training\\n\",\n",
    "    \"history_phase2 = model.fit(\\n\",\n",
    "    \"    train_generator,\\n\",\n",
    "    \"    epochs=30,\\n\",\n",
    "    \"    initial_epoch=history_phase1.epoch[-1],\\n\",\n",
    "    \"    validation_data=val_generator,\\n\",\n",
    "    \"    callbacks=callbacks,\\n\",\n",
    "    \"    verbose=1\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Plot Training History\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def plot_training_history(history1, history2=None):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Plot training and validation accuracy/loss\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Combine histories\\n\",\n",
    "    \"    if history2:\\n\",\n",
    "    \"        acc = history1.history['accuracy'] + history2.history['accuracy']\\n\",\n",
    "    \"        val_acc = history1.history['val_accuracy'] + history2.history['val_accuracy']\\n\",\n",
    "    \"        loss = history1.history['loss'] + history2.history['loss']\\n\",\n",
    "    \"        val_loss = history1.history['val_loss'] + history2.history['val_loss']\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        acc = history1.history['accuracy']\\n\",\n",
    "    \"        val_acc = history1.history['val_accuracy']\\n\",\n",
    "    \"        loss = history1.history['loss']\\n\",\n",
    "    \"        val_loss = history1.history['val_loss']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    epochs_range = range(len(acc))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=(14, 5))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot accuracy\\n\",\n",
    "    \"    plt.subplot(1, 2, 1)\\n\",\n",
    "    \"    plt.plot(epochs_range, acc, label='Training Accuracy')\\n\",\n",
    "    \"    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\\n\",\n",
    "    \"    plt.axvline(x=20, color='r', linestyle='--', label='Fine-tuning starts')\\n\",\n",
    "    \"    plt.legend(loc='lower right')\\n\",\n",
    "    \"    plt.title('Training and Validation Accuracy')\\n\",\n",
    "    \"    plt.xlabel('Epoch')\\n\",\n",
    "    \"    plt.ylabel('Accuracy')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot loss\\n\",\n",
    "    \"    plt.subplot(1, 2, 2)\\n\",\n",
    "    \"    plt.plot(epochs_range, loss, label='Training Loss')\\n\",\n",
    "    \"    plt.plot(epochs_range, val_loss, label='Validation Loss')\\n\",\n",
    "    \"    plt.axvline(x=20, color='r', linestyle='--', label='Fine-tuning starts')\\n\",\n",
    "    \"    plt.legend(loc='upper right')\\n\",\n",
    "    \"    plt.title('Training and Validation Loss')\\n\",\n",
    "    \"    plt.xlabel('Epoch')\\n\",\n",
    "    \"    plt.ylabel('Loss')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plot_training_history(history_phase1, history_phase2)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Evaluate Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate on validation set\\n\",\n",
    "    \"print(\\\"\\\\nEvaluating model on validation set...\\\")\\n\",\n",
    "    \"val_loss, val_accuracy, val_top2_acc = model.evaluate(val_generator, verbose=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n{'='*50}\\\")\\n\",\n",
    "    \"print(f\\\"Validation Loss: {val_loss:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Validation Accuracy: {val_accuracy*100:.2f}%\\\")\\n\",\n",
    "    \"print(f\\\"Validation Top-2 Accuracy: {val_top2_acc*100:.2f}%\\\")\\n\",\n",
    "    \"print(f\\\"{'='*50}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 11. Confusion Matrix & Classification Report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.metrics import classification_report, confusion_matrix\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get predictions\\n\",\n",
    "    \"val_generator.reset()\\n\",\n",
    "    \"predictions = model.predict(val_generator, verbose=1)\\n\",\n",
    "    \"y_pred = np.argmax(predictions, axis=1)\\n\",\n",
    "    \"y_true = val_generator.classes\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Confusion matrix\\n\",\n",
    "    \"cm = confusion_matrix(y_true, y_pred)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \\n\",\n",
    "    \"            xticklabels=CLASS_NAMES, \\n\",\n",
    "    \"            yticklabels=CLASS_NAMES)\\n\",\n",
    "    \"plt.title('Confusion Matrix')\\n\",\n",
    "    \"plt.ylabel('True Label')\\n\",\n",
    "    \"plt.xlabel('Predicted Label')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Classification report\\n\",\n",
    "    \"print(\\\"\\\\nClassification Report:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"report = classification_report(y_true, y_pred, target_names=CLASS_NAMES)\\n\",\n",
    "    \"print(report)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 12. Test Predictions on Sample Images\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def predict_and_visualize(model, generator, num_samples=6):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Visualize predictions on sample images\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    images, labels = next(generator)\\n\",\n",
    "    \"    predictions = model.predict(images[:num_samples])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=(15, 10))\\n\",\n",
    "    \"    for i in range(num_samples):\\n\",\n",
    "    \"        plt.subplot(2, 3, i"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
